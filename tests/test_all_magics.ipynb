{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Kernel - Complete Magic Commands Test Suite\n",
    "\n",
    "This notebook tests all available magic commands in the LLM Kernel.\n",
    "It can be run via CLI using: `jupyter nbconvert --to notebook --execute test_all_magics.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Model Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: List all available models\n",
    "%llm_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Show current active model\n",
    "%llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Switch to a different model (if available)\n",
    "%llm_model gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Switch back\n",
    "%llm_model gpt-4o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic LLM Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Simple cell magic query\n",
    "%%llm\n",
    "What is 2 + 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Query with specific model\n",
    "%%llm --model=gpt-4o-mini\n",
    "Explain Python list comprehensions in one sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Model-specific shortcuts (if available)\n",
    "%%llm_gpt4\n",
    "What is the capital of France?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Claude shortcut (if available)\n",
    "%%llm_claude\n",
    "What is the meaning of life?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chat Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Enable chat mode\n",
    "%llm_chat on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Chat query (no magic needed)\n",
    "Hello! Can you see this message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Another chat query\n",
    "What was my previous question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Disable chat mode\n",
    "%llm_chat off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Context Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Show current status\n",
    "%llm_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Pin a cell\n",
    "# First create a cell with important context\n",
    "important_data = {\"key\": \"value\", \"number\": 42}\n",
    "print(\"This cell contains important data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Pin the previous cell (adjust cell number as needed)\n",
    "%llm_pin_cell -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Show pinned cells\n",
    "%llm_pin_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Unpin a cell\n",
    "%llm_unpin_cell -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Set context strategy\n",
    "%llm_context smart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Show token usage\n",
    "%llm_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Show context cells\n",
    "%llm_show_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Compare multiple models\n",
    "%%llm_compare gpt-4o gpt-4o-mini\n",
    "What is recursion in programming?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Show configuration UI\n",
    "%llm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Show kernel info\n",
    "%llm_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conversation Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Show conversation history\n",
    "%llm_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Export context\n",
    "%llm_export_context test_context.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Clear conversation\n",
    "%llm_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Import context back\n",
    "%llm_import_context test_context.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multimodal Support (if files available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: List uploaded files\n",
    "%llm_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Show cache info\n",
    "%llm_cache_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: List cached files\n",
    "%llm_cache_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Uncomment to test with actual files\n",
    "# %llm_image path/to/image.png\n",
    "# %llm_pdf_native path/to/document.pdf\n",
    "# %llm_paste  # After copying something to clipboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. MCP (Model Context Protocol) - if configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: List MCP servers\n",
    "%llm_mcp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Show MCP status\n",
    "%llm_mcp_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Show cost tracking\n",
    "%llm_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Show context graph visualization\n",
    "%llm_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Reset kernel state\n",
    "%llm_reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Summary\n",
    "\n",
    "This notebook has tested all major magic commands:\n",
    "\n",
    "### ✅ Model Management\n",
    "- `%llm_models` - List available models\n",
    "- `%llm_model` - Show/switch active model\n",
    "\n",
    "### ✅ Querying\n",
    "- `%%llm` - Query the LLM\n",
    "- `%%llm_gpt4`, `%%llm_claude` - Model-specific queries\n",
    "- `%%llm_compare` - Compare model responses\n",
    "\n",
    "### ✅ Chat Mode\n",
    "- `%llm_chat` - Toggle chat mode\n",
    "\n",
    "### ✅ Context Management\n",
    "- `%llm_status` - Show kernel status\n",
    "- `%llm_pin_cell` - Pin/unpin cells\n",
    "- `%llm_context` - Set context strategy\n",
    "- `%llm_tokens` - Show token usage\n",
    "- `%llm_show_context` - Display context cells\n",
    "\n",
    "### ✅ Configuration\n",
    "- `%llm_config` - Show configuration UI\n",
    "- `%llm_info` - Show kernel information\n",
    "\n",
    "### ✅ Conversation\n",
    "- `%llm_history` - Show conversation history\n",
    "- `%llm_clear` - Clear conversation\n",
    "- `%llm_export_context` - Export context\n",
    "- `%llm_import_context` - Import context\n",
    "\n",
    "### ✅ Multimodal\n",
    "- `%llm_image` - Add images\n",
    "- `%llm_pdf_native` - Upload PDFs\n",
    "- `%llm_paste` - Paste from clipboard\n",
    "- `%llm_files_list` - List uploaded files\n",
    "- `%llm_cache_info` - Cache information\n",
    "\n",
    "### ✅ MCP Integration\n",
    "- `%llm_mcp_list` - List MCP servers\n",
    "- `%llm_mcp_status` - MCP status\n",
    "\n",
    "### ✅ Advanced\n",
    "- `%llm_cost` - Show cost tracking\n",
    "- `%llm_graph` - Visualize context\n",
    "- `%llm_reset` - Reset kernel state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test: Verify kernel is still responsive\n",
    "print(\"All tests completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Kernel",
   "language": "python",
   "name": "llm_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}