{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Kernel Test Notebook\n",
    "\n",
    "Test the LLM kernel functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from LLM Kernel!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test basic Python execution\n",
    "print(\"Hello from LLM Kernel!\")\n",
    "x = 42\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Available LLM Models:\n",
      "  ‚ö™ gpt-4o\n",
      "  ‚úÖ (active) gpt-4o-mini\n",
      "  ‚ö™ gpt-4\n",
      "  ‚ö™ gpt-3.5-turbo\n",
      "  ‚ö™ claude-3-opus\n",
      "  ‚ö™ claude-3-sonnet\n",
      "  ‚ö™ claude-3-haiku\n",
      "  ‚ö™ llama3\n",
      "  ‚ö™ codellama\n"
     ]
    }
   ],
   "source": [
    "# List available models\n",
    "%llm_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ LLM Kernel Status\n",
      "==================================================\n",
      "Active Model: gpt-4o-mini\n",
      "Available Models: 9\n",
      "Conversation History: 0 exchanges\n",
      "\n",
      "Context Strategy: smart\n",
      "Executed Cells: 2\n",
      "Pinned Cells: 0\n"
     ]
    }
   ],
   "source": [
    "# Check kernel status\n",
    "%llm_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (368385269.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mWhat is 2 + 2?\u001b[39m\n                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Test LLM query\n",
    "%%llm\n",
    "What is 2 + 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Display mode set to: chat\n",
      "üí¨ Started new chat thread: 6cff47df\n",
      "üìù Create a new cell below and use %%llm to start chatting!\n"
     ]
    }
   ],
   "source": [
    "# Switch to chat display mode\n",
    "%llm_display chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Jupyter kernel is like a computer program that runs your code in a Jupyter Notebook. When you write code in a Jupyter Notebook and run it, the notebook sends that code to the kernel, which processes it and sends back the output. Each programming language you can use in Jupyter (like Python, R, or Julia) has its own specific kernel. So, a kernel helps connect the notebook interface with the programming language, allowing you to execute code and see results interactively.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A Jupyter kernel is like a computer program that runs your code in a Jupyter Notebook. When you write code in a Jupyter Notebook and run it, the notebook sends that code to the kernel, which processes it and sends back the output. Each programming language you can use in Jupyter (like Python, R, or Julia) has its own specific kernel. So, a kernel helps connect the notebook interface with the programming language, allowing you to execute code and see results interactively.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%llm\n",
    "Explain what a Jupyter kernel is in simple terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Arial, sans-serif; max-width: 800px;\"><h3>üí¨ LLM Conversation History</h3>\n",
       "            <div style=\"margin: 10px 0; padding: 10px; background: #e3f2fd; border-radius: 10px;\">\n",
       "                <strong>üë§ User:</strong><br>\n",
       "                <pre style=\"white-space: pre-wrap; margin: 5px 0;\">Explain what a Jupyter kernel is in simple terms.\n",
       "</pre>\n",
       "            </div>\n",
       "            \n",
       "                <div style=\"margin: 10px 0 20px 40px; padding: 10px; background: #f5f5f5; border-radius: 10px;\">\n",
       "                    <strong>ü§ñ gpt-4o-mini:</strong><br>\n",
       "                    <pre style=\"white-space: pre-wrap; margin: 5px 0;\">A Jupyter kernel is like a computer program that runs your code in a Jupyter Notebook. When you write code in a Jupyter Notebook and run it, the notebook sends that code to the kernel, which processes it and sends back the output. Each programming language you can use in Jupyter (like Python, R, or Julia) has its own specific kernel. So, a kernel helps connect the notebook interface with the programming language, allowing you to execute code and see results interactively.</pre>\n",
       "                </div>\n",
       "                </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show conversation history\n",
    "%llm_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell dependency tracking\n",
    "def greet(name):\n",
    "    return f\"Hello, {name}!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, LLM Kernel!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell depends on the previous one\n",
    "greet(\"LLM Kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Pinned cell 9\n"
     ]
    }
   ],
   "source": [
    "# Pin a cell for context\n",
    "%llm_pin_cell 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!set LLM_KERNEL_DEBUG=ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm ready! What specific test do you have in mind? Please provide some details so I can assist you better.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm ready! What specific test do you have in mind? Please provide some details so I can assist you better.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%llm\n",
    "Let's test this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is a high-level, interpreted programming language known for its readability and simplicity, making it an excellent choice for beginners as well as experienced developers. It was created by Guido van Rossum and first released in 1991. Python supports multiple programming paradigms, including procedural, object-oriented, and functional programming.\n",
      "\n",
      "Key features of Python include:\n",
      "\n",
      "1. **Readable Syntax**: Python emphasizes code readability and simplicity, allowing developers to write clear and logical code for both small and large-scale projects.\n",
      "\n",
      "2. **Dynamic Typing and Memory Management**: Python is dynamically typed, meaning you don't need to declare the data type of a variable before using it. It also handles memory management automatically through garbage collection.\n",
      "\n",
      "3. **Extensive Standard Library**: Python comes with a vast standard library that provides modules and functions for many common tasks, including file handling, web development, data manipulation, and more.\n",
      "\n",
      "4. **Cross-Platform Compatibility**: Python is available on various operating systems, including Windows, macOS, and Linux, enabling developers to write code that runs on multiple platforms.\n",
      "\n",
      "5. **Strong Community Support**: Python has a large and active community, which means a wealth of resources, libraries, and frameworks are available to assist developers. Some popular frameworks and libraries include Django (web development), Pandas (data analysis), NumPy (numerical computing), TensorFlow (machine learning), and Matplotlib (data visualization).\n",
      "\n",
      "6. **Open Source**: Python is open-source software, meaning its source code is freely available for anyone to use, modify, and distribute.\n",
      "\n",
      "Python is widely used in various domains, such as web development, data analysis, artificial intelligence, scientific computing, automation, and more. Its versatility and ease of use have contributed to its status as one of the most popular programming languages in the world.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            var cell = Jupyter.notebook.insert_cell_below('code');\n",
       "            cell.set_text('%%llm_chat\\n# Continue your conversation here...');\n",
       "            cell.focus_cell();\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Python is a high-level, interpreted programming language known for its readability and simplicity, making it an excellent choice for beginners as well as experienced developers. It was created by Guido van Rossum and first released in 1991. Python supports multiple programming paradigms, including procedural, object-oriented, and functional programming.\\n\\nKey features of Python include:\\n\\n1. **Readable Syntax**: Python emphasizes code readability and simplicity, allowing developers to write clear and logical code for both small and large-scale projects.\\n\\n2. **Dynamic Typing and Memory Management**: Python is dynamically typed, meaning you don't need to declare the data type of a variable before using it. It also handles memory management automatically through garbage collection.\\n\\n3. **Extensive Standard Library**: Python comes with a vast standard library that provides modules and functions for many common tasks, including file handling, web development, data manipulation, and more.\\n\\n4. **Cross-Platform Compatibility**: Python is available on various operating systems, including Windows, macOS, and Linux, enabling developers to write code that runs on multiple platforms.\\n\\n5. **Strong Community Support**: Python has a large and active community, which means a wealth of resources, libraries, and frameworks are available to assist developers. Some popular frameworks and libraries include Django (web development), Pandas (data analysis), NumPy (numerical computing), TensorFlow (machine learning), and Matplotlib (data visualization).\\n\\n6. **Open Source**: Python is open-source software, meaning its source code is freely available for anyone to use, modify, and distribute.\\n\\nPython is widely used in various domains, such as web development, data analysis, artificial intelligence, scientific computing, automation, and more. Its versatility and ease of use have contributed to its status as one of the most popular programming languages in the world.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%llm_chat \n",
    "What is python?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 3) (3775352719.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mI'm thinking of a number between one and ten\u001b[39m\n     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 3)\n"
     ]
    }
   ],
   "source": [
    "%llm_chat\n",
    "\n",
    "I'm thinking of a number between one and ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we're continuing the guessing game, please let me know if my guess of 5 is too high, too low, or correct! Alternatively, if you'd like to change the subject or ask something else, I'm here for that too!\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            (function() {\n",
       "                // For JupyterLab\n",
       "                try {\n",
       "                    const lab = document.querySelector('[data-jp-app-dir]').__vue_app__.config.globalProperties.$jupyter;\n",
       "                    if (lab && lab.commands) {\n",
       "                        lab.commands.execute('notebook:insert-cell-below').then(() => {\n",
       "                            setTimeout(() => {\n",
       "                                const nb = lab.shell.currentWidget;\n",
       "                                if (nb && nb.content) {\n",
       "                                    const cell = nb.content.activeCell;\n",
       "                                    if (cell) {\n",
       "                                        cell.model.value.text = '%%llm_chat\\n# Continue your conversation here...';\n",
       "                                        cell.editor.focus();\n",
       "                                    }\n",
       "                                }\n",
       "                            }, 100);\n",
       "                        });\n",
       "                        return;\n",
       "                    }\n",
       "                } catch(e) {}\n",
       "                \n",
       "                // Alternative approach for JupyterLab\n",
       "                try {\n",
       "                    const app = window.jupyterapp || window.jupyterlab;\n",
       "                    if (app) {\n",
       "                        app.commands.execute('notebook:insert-cell-below');\n",
       "                        setTimeout(() => {\n",
       "                            app.commands.execute('notebook:replace-selection').then(() => {\n",
       "                                const cell = app.shell.currentWidget.content.activeCell;\n",
       "                                if (cell) {\n",
       "                                    cell.model.value.text = '%%llm_chat\\n# Continue your conversation here...';\n",
       "                                }\n",
       "                            });\n",
       "                        }, 100);\n",
       "                        return;\n",
       "                    }\n",
       "                } catch(e) {}\n",
       "                \n",
       "                // For classic Jupyter Notebook\n",
       "                if (typeof Jupyter !== 'undefined' && Jupyter.notebook) {\n",
       "                    var cell = Jupyter.notebook.insert_cell_below('code');\n",
       "                    cell.set_text('%%llm_chat\\n# Continue your conversation here...');\n",
       "                    cell.focus_cell();\n",
       "                    return;\n",
       "                }\n",
       "                \n",
       "                console.log('Could not find notebook API');\n",
       "            })();\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"If we're continuing the guessing game, please let me know if my guess of 5 is too high, too low, or correct! Alternatively, if you'd like to change the subject or ask something else, I'm here for that too!\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%llm_chat\n",
    "# Continue your conversation here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `now` not found.\n"
     ]
    }
   ],
   "source": [
    "what now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Chat mode: ON\n",
      "‚ÑπÔ∏è  Now every %%llm query maintains conversation context\n",
      "üìù Just use %%llm in any cell to continue the conversation\n",
      "Object `now` not found.\n"
     ]
    }
   ],
   "source": [
    "%llm_chat\n",
    "can you hear me now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4o-mini]\n",
      "----------------------------------------\n",
      "That depends on what you're interested in! Here are a few options:\n",
      "\n",
      "1. **Ask Questions**: You can ask about a specific topic, and I'll do my best to provide answers.\n",
      "2. **Quizzes**: I can create a trivia quiz or a puzzle for you to solve.\n",
      "3. **Learning**: If there's something specific you want to learn about, let me know, and I can provide information.\n",
      "4. **Creative Writing**: We can write a story or poem together.\n",
      "5. **Brainstorm Ideas**: If you have a project or topic in mind, we can brainstorm ideas together.\n",
      "\n",
      "Let me know what appeals to you!\n",
      "\n",
      "========================================\n",
      "üí¨ Continue in next cell with %%llm\n"
     ]
    }
   ],
   "source": [
    "What now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4o-mini]\n",
      "----------------------------------------\n",
      "We're in a text-based conversation mode. You can interact with me by typing questions, prompts, or topics you'd like to discuss, and I'll respond accordingly. If you have a specific mode or topic in mind, let me know!\n",
      "\n",
      "========================================\n",
      "üí¨ Continue in next cell with %%llm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "What mode are we in?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4o-mini]\n",
      "----------------------------------------\n",
      "It seems like your message got cut off or might be incomplete. Could you please clarify what you meant by \"ss\"? I'm here to help!\n",
      "\n",
      "========================================\n",
      "üí¨ Continue in next cell with %%llm\n"
     ]
    }
   ],
   "source": [
    "ss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Chat mode: OFF\n",
      "‚ÑπÔ∏è  Use %%llm for one-off queries\n"
     ]
    }
   ],
   "source": [
    "%llm_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Chat mode: ON\n",
      "‚ÑπÔ∏è  Now every %%llm query maintains conversation context\n",
      "üìù Just use %%llm in any cell to continue the conversation\n"
     ]
    }
   ],
   "source": [
    "%llm_chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rewe\n",
    "sadasds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Kernel",
   "language": "python",
   "name": "llm_kernel"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
