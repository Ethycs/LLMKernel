{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Reranking & Custom Meta Functions Demo\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. LLM-based context reranking by relevance\n",
    "2. Custom meta functions for filtering, ranking, and transforming context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Chat mode: ON\n",
      "üìì Notebook context mode: ON\n",
      "üìù Just type in any cell to chat!\n",
      "üí° Your notebook cells are now the LLM's context window!\n"
     ]
    }
   ],
   "source": [
    "# Enable chat mode\n",
    "%llm_chat on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Some Context\n",
    "\n",
    "Let's create a variety of cells with different topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                        <div style=\"margin: 10px 0 20px 40px; padding: 10px; background: #f5f5f5; \n",
       "                                    border-radius: 10px; border-left: 3px solid #2196F3;\">\n",
       "                            <strong>ü§ñ gpt-4o:</strong><br>\n",
       "                            <div style=\"margin-top: 8px; white-space: pre-wrap;\">This cell defines a simple Python function called `hello_world`. Here's a breakdown of what each part does:\n",
       "\n",
       "- `def hello_world():` - This line defines a function named `hello_world`. The `def` keyword is used to define a function, and `hello_world` is the name you‚Äôre giving to the function.\n",
       "  \n",
       "- `print(\"Hello, World!\")` - Inside the function, this line uses the `print` function to output the string \"Hello, World!\" to the console.\n",
       "\n",
       "- `hello_world()` - This line calls the `hello_world` function, which means the function is executed and the string \"Hello, World!\" is printed to the console.\n",
       "\n",
       "The function doesn‚Äôt take any arguments, and its sole purpose is to print a greeting message when called. This is often one of the first programs written by people learning a new programming language.</div>\n",
       "                        </div>\n",
       "                        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell about Python basics\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "    \n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                        <div style=\"margin: 10px 0 20px 40px; padding: 10px; background: #f5f5f5; \n",
       "                                    border-radius: 10px; border-left: 3px solid #2196F3;\">\n",
       "                            <strong>ü§ñ gpt-4o:</strong><br>\n",
       "                            <div style=\"margin-top: 8px; white-space: pre-wrap;\">This code snippet demonstrates a simple linear relationship between two variables \\( X \\) and \\( y \\). Here's a breakdown of what's happening:\n",
       "\n",
       "1. **Define the Input (X):**  \n",
       "   `X` is defined as a NumPy array containing values `[1, 2, 3, 4, 5]`.\n",
       "\n",
       "2. **Define the Output (y):**  \n",
       "   `y` is calculated using the linear equation \\( y = 2X + 1 \\). This means for each element in `X`, the corresponding element in `y` is determined by multiplying the element in `X` by 2 and then adding 1.\n",
       "\n",
       "3. **Print Statements:**  \n",
       "   - The script prints the linear relationship equation `y = 2x + 1`.\n",
       "   - It also prints the values of `X` and the resulting `y`.\n",
       "\n",
       "This straightforward example illustrates how linear relationships work in the context of simple linear regression, where `y` is dependent on `X` with a slope of 2 and an intercept of 1. If you have questions about linear regression or need further elaboration, feel free to ask!</div>\n",
       "                        </div>\n",
       "                        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell about machine learning\n",
    "import numpy as np\n",
    "\n",
    "# Simple linear regression example\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "y = 2 * X + 1\n",
    "print(f\"Linear relationship: y = 2x + 1\")\n",
    "print(f\"X: {X}\")\n",
    "print(f\"y: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                        <div style=\"margin: 10px 0 20px 40px; padding: 10px; background: #f5f5f5; \n",
       "                                    border-radius: 10px; border-left: 3px solid #2196F3;\">\n",
       "                            <strong>ü§ñ gpt-4o:</strong><br>\n",
       "                            <div style=\"margin-top: 8px; white-space: pre-wrap;\">Gradient descent is an optimization algorithm used to minimize the loss function in machine learning and statistical models. It is a critical part of training models, especially in neural networks and linear regression, among other applications.\n",
       "\n",
       "Here's how gradient descent works:\n",
       "\n",
       "1. **Initialization**:  \n",
       "   - Begin with an initial guess for the parameters (weights) of your model. These are usually set randomly.\n",
       "\n",
       "2. **Compute the Gradient**:  \n",
       "   - Calculate the gradient of the loss function with respect to each parameter. The gradient is a vector of partial derivatives, providing the slope of the tangent to the error surface.\n",
       "\n",
       "3. **Update Parameters**:  \n",
       "   - Adjust the parameters in the opposite direction of the gradient. This step is crucial because it means you are moving towards the minimum value of the loss function. The update rule for a parameter \\( \\theta \\) is generally given by:\n",
       "     \\[\n",
       "     \\theta = \\theta - \\eta \\cdot \\nabla J(\\theta)\n",
       "     \\]\n",
       "     where \\( \\eta \\) is the learning rate, a small, positive value that determines how big each update step is, and \\( \\nabla J(\\theta) \\) is the gradient of the loss function \\( J \\) at \\( \\theta \\).\n",
       "\n",
       "4. **Iterate**:  \n",
       "   - Repeat the process of computing the gradient and updating the parameters until convergence. Convergence is typically determined when changes in the loss function become negligible between iterations or after a predefined number of iterations (epochs).\n",
       "\n",
       "There are several variations of gradient descent, each with its advantages and trade-offs:\n",
       "\n",
       "- **Batch Gradient Descent**: Uses the entire dataset to compute the gradient at each step. This can be computationally intensive and slow for large datasets.\n",
       "\n",
       "- **Stochastic Gradient Descent (SGD)**: Updates the parameters for each training example, making it much faster but with higher variance in updates.\n",
       "\n",
       "- **Mini-batch Gradient Descent**: A compromise between batch and stochastic methods, using a small, randomly selected portion of the dataset (mini-batch) to compute each update. This method is widely used in practice because it reduces variance in parameter updates and can make use of the parallel architecture of modern hardware.\n",
       "\n",
       "Gradient descent is a powerful algorithm that suits many optimization problems despite having its limitations, such as potentially getting stuck in local minima or being sensitive to the choice of learning rate. Various advanced techniques such as momentum, adaptive learning rates (e.g., Adam, RMSProp), and regularization strategies have been developed to enhance its performance.</div>\n",
       "                        </div>\n",
       "                        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "What is gradient descent and how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell about web development\n",
    "html_template = \"\"\"\n",
    "<html>\n",
    "  <head><title>My Page</title></head>\n",
    "  <body>\n",
    "    <h1>Welcome!</h1>\n",
    "    <p>This is a simple HTML page.</p>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "print(\"Basic HTML structure created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random cell about cooking\n",
    "recipe = {\n",
    "    \"name\": \"Chocolate Chip Cookies\",\n",
    "    \"ingredients\": [\"flour\", \"butter\", \"sugar\", \"eggs\", \"chocolate chips\"],\n",
    "    \"time\": \"30 minutes\"\n",
    "}\n",
    "print(f\"Recipe: {recipe['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                        <div style=\"margin: 10px 0 20px 40px; padding: 10px; background: #f5f5f5; \n",
       "                                    border-radius: 10px; border-left: 3px solid #2196F3;\">\n",
       "                            <strong>ü§ñ gpt-4o:</strong><br>\n",
       "                            <div style=\"margin-top: 8px; white-space: pre-wrap;\">Sure! Neural networks are a class of artificial intelligence models inspired by the human brain. They consist of interconnected layers of nodes, or neurons, that process input data and generate output. Here‚Äôs a brief overview of how they work:\n",
       "\n",
       "1. **Structure**: \n",
       "   - Neural networks are composed of layers: an input layer, one or more hidden layers, and an output layer.\n",
       "   - Each layer consists of nodes (or neurons), and every node in a layer is usually connected to every node in the next layer.\n",
       "\n",
       "2. **Neurons**:\n",
       "   - Each neuron receives one or more inputs, applies a weight to each input, sums them, and passes the result through an activation function to produce an output.\n",
       "   - Activation functions introduce non-linearity to the model, allowing it to learn complex patterns. Common activation functions include ReLU, Sigmoid, and Tanh.\n",
       "\n",
       "3. **Weights and Biases**:\n",
       "   - Weights determine the strength and direction of the input signals, essentially telling each neuron how important its inputs are.\n",
       "   - Biases are additional parameters that allow the model to fit the data better, by providing another degree of freedom.\n",
       "\n",
       "4. **Training**:\n",
       "   - Neural networks learn through a process called training, which involves adjusting weights and biases to minimize the difference between the predicted and actual outputs.\n",
       "   - Training is typically done using a method called backpropagation and involves optimization algorithms like gradient descent to update weights and biases.\n",
       "\n",
       "5. **Forward Propagation**:\n",
       "   - Input data is fed into the network, and it propagates through the layers (forward pass) to generate an output.\n",
       "\n",
       "6. **Backpropagation**:\n",
       "   - After getting the output, the error (difference between the network‚Äôs prediction and the actual outcome) is calculated.\n",
       "   - The error is then propagated back through the network to update the weights and biases in such a way that minimizes the error in future predictions.\n",
       "\n",
       "7. **Types of Neural Networks**:\n",
       "   - *Feedforward Neural Networks*: Data moves in one direction, from input to output.\n",
       "   - *Convolutional Neural Networks (CNNs)*: Specialized for processing grid-like topologies such as images.\n",
       "   - *Recurrent Neural Networks (RNNs)*: Suited for sequence prediction problems; they maintain a form of memory.\n",
       "   - *Generative Adversarial Networks (GANs)*: Consist of two networks, a generator and a discriminator, that compete in a zero-sum game.\n",
       "\n",
       "Neural networks have become the backbone of many modern AI applications, from image and voice recognition to language processing and beyond, due to their ability to model complex, non-linear relationships in data.</div>\n",
       "                        </div>\n",
       "                        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Can you explain neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: LLM-Based Reranking\n",
    "\n",
    "Now let's rerank cells by relevance to a specific query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                        <div style=\"margin: 10px 0 20px 40px; padding: 10px; background: #f5f5f5; \n",
       "                                    border-radius: 10px; border-left: 3px solid #2196F3;\">\n",
       "                            <strong>ü§ñ gpt-4o:</strong><br>\n",
       "                            <div style=\"margin-top: 8px; white-space: pre-wrap;\">Certainly! However, I want to clarify that as an AI language model, I don't have direct access to a \"current context\" like a context memory or session log that you can view. Each query is processed independently, and I do not retain memory of past interactions. If you have specific context or details you want to include in our conversation, feel free to provide that information, and I'll do my best to assist you!</div>\n",
       "                        </div>\n",
       "                        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, let's see the current context order\n",
    "%llm_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                        <div style=\"margin: 10px 0 20px 40px; padding: 10px; background: #f5f5f5; \n",
       "                                    border-radius: 10px; border-left: 3px solid #2196F3;\">\n",
       "                            <strong>ü§ñ gpt-4o:</strong><br>\n",
       "                            <div style=\"margin-top: 8px; white-space: pre-wrap;\">Certainly! Please provide the list or text you'd like me to rerank by relevance to machine learning and neural networks.</div>\n",
       "                        </div>\n",
       "                        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rerank by relevance to machine learning\n",
    "%llm_rerank \"machine learning and neural networks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                        <div style=\"margin: 10px 0 20px 40px; padding: 10px; background: #f5f5f5; \n",
       "                                    border-radius: 10px; border-left: 3px solid #2196F3;\">\n",
       "                            <strong>ü§ñ gpt-4o:</strong><br>\n",
       "                            <div style=\"margin-top: 8px; white-space: pre-wrap;\">It seems like you're using some form of command to enable a \"chat mode\" or check a new order. However, I don't have direct control over chat modes or any external systems for orders. Could you clarify or provide more context on what you're trying to achieve?</div>\n",
       "                        </div>\n",
       "                        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the new order\n",
    "%llm_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just show ranking without reordering\n",
    "%llm_rerank --show \"web development\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only top 5 most relevant cells\n",
    "%llm_rerank --top=5 \"Python programming\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear reranking to restore original order\n",
    "%llm_rerank_clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Custom Meta Functions\n",
    "\n",
    "Define your own context processing logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%meta filter\n",
    "def filter_cells(messages):\n",
    "    \"\"\"Filter out cells that are too short or contain specific keywords.\"\"\"\n",
    "    filtered = []\n",
    "    \n",
    "    for msg in messages:\n",
    "        content = msg['content']\n",
    "        \n",
    "        # Skip very short messages\n",
    "        if len(content) < 20:\n",
    "            continue\n",
    "            \n",
    "        # Skip cells about cooking (as an example)\n",
    "        if 'recipe' in content.lower() or 'cooking' in content.lower():\n",
    "            continue\n",
    "            \n",
    "        filtered.append(msg)\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%meta ranking\n",
    "def rank_cells(messages, query):\n",
    "    \"\"\"Custom ranking based on keyword matching.\"\"\"\n",
    "    # Simple keyword-based ranking\n",
    "    query_words = set(query.lower().split())\n",
    "    \n",
    "    scored_messages = []\n",
    "    for msg in messages:\n",
    "        content_words = set(msg['content'].lower().split())\n",
    "        score = len(query_words.intersection(content_words))\n",
    "        scored_messages.append((score, msg))\n",
    "    \n",
    "    # Sort by score (descending)\n",
    "    scored_messages.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Return reordered messages\n",
    "    return [msg for score, msg in scored_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%meta transform\n",
    "def transform_context(messages):\n",
    "    \"\"\"Add metadata to each message.\"\"\"\n",
    "    transformed = []\n",
    "    \n",
    "    for i, msg in enumerate(messages):\n",
    "        # Add position and length metadata\n",
    "        new_msg = msg.copy()\n",
    "        new_msg['content'] = f\"[Position {i+1}, Length {len(msg['content'])}]\\n{msg['content']}\"\n",
    "        transformed.append(new_msg)\n",
    "    \n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List defined meta functions\n",
    "%llm_meta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the filter function\n",
    "%llm_apply_meta filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply custom ranking\n",
    "%llm_apply_meta ranking \"machine learning neural networks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all meta functions in sequence\n",
    "%llm_apply_meta all \"Python programming\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the transformed context\n",
    "%llm_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Advanced Meta Functions\n",
    "\n",
    "More sophisticated examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%meta ranking\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def rank_cells(messages, query):\n",
    "    \"\"\"Semantic ranking using TF-IDF-like scoring.\"\"\"\n",
    "    # Tokenize query\n",
    "    query_tokens = re.findall(r'\\w+', query.lower())\n",
    "    query_freq = Counter(query_tokens)\n",
    "    \n",
    "    scored = []\n",
    "    for msg in messages:\n",
    "        # Tokenize message\n",
    "        msg_tokens = re.findall(r'\\w+', msg['content'].lower())\n",
    "        msg_freq = Counter(msg_tokens)\n",
    "        \n",
    "        # Calculate similarity score\n",
    "        score = 0\n",
    "        for token, freq in query_freq.items():\n",
    "            if token in msg_freq:\n",
    "                # Higher score for more occurrences\n",
    "                score += min(freq, msg_freq[token]) * (1 + len(token) / 10)\n",
    "        \n",
    "        # Boost score for assistant responses about the topic\n",
    "        if msg['role'] == 'assistant' and any(t in msg_tokens for t in query_tokens):\n",
    "            score *= 1.5\n",
    "            \n",
    "        scored.append((score, msg))\n",
    "    \n",
    "    # Sort by score\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Return reordered, keeping at least some context\n",
    "    result = [msg for _, msg in scored]\n",
    "    \n",
    "    # Ensure we have at least 3 messages\n",
    "    if len(result) < 3 and len(messages) >= 3:\n",
    "        return result + messages[:3-len(result)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the new ranking\n",
    "%llm_apply_meta ranking \"neural networks gradient descent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You now have powerful tools for context management:\n",
    "\n",
    "1. **LLM-based reranking** - Let the AI intelligently reorder cells by relevance\n",
    "2. **Custom meta functions** - Define your own logic for filtering, ranking, and transforming\n",
    "3. **Flexible application** - Apply functions individually or in sequence\n",
    "\n",
    "This gives you complete control over what context the LLM sees and in what order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable chat mode\n",
    "%llm_chat off"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Kernel",
   "language": "python",
   "name": "llm_kernel"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
