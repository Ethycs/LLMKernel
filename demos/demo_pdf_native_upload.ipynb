{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Native PDF Upload Demo\n",
    "\n",
    "This notebook demonstrates the native PDF upload functionality using OpenAI's Assistants API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current model\n",
    "%llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable chat mode\n",
    "%llm_chat on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload a PDF\n",
    "\n",
    "You can upload PDFs in three ways:\n",
    "\n",
    "1. **Copy & Paste**: Copy a PDF file (Ctrl+C) and use `%llm_paste`\n",
    "2. **Direct upload**: Use `%llm_pdf_native path/to/file.pdf`\n",
    "3. **Convert to images**: Use `%llm_pdf path/to/file.pdf` (for vision models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Copy a PDF file with Ctrl+C, then:\n",
    "# %llm_paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Direct upload (replace with your PDF path)\n",
    "# %llm_pdf_native path/to/your/document.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the PDF\n",
    "\n",
    "Once uploaded, the PDF is part of your conversation context. You can ask questions about it in any subsequent cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries (after uploading a PDF):\n",
    "# What is the main topic of this document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you summarize the key findings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the references/citations from this paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Uploaded Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List uploaded files\n",
    "%llm_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear uploaded files from conversation\n",
    "# %llm_files_clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How It Works\n",
    "\n",
    "For OpenAI models (GPT-4o, etc.):\n",
    "1. PDFs are uploaded to OpenAI using the Files API\n",
    "2. The kernel automatically uses the Assistants API when files are present\n",
    "3. The assistant can read and analyze the PDF content directly\n",
    "4. Files are cached locally to avoid re-uploading\n",
    "\n",
    "For other providers:\n",
    "- Claude: PDFs are embedded directly in messages\n",
    "- Vision models: PDFs can be converted to images with `%llm_pdf`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Kernel",
   "language": "python",
   "name": "llm_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}