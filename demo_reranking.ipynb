{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Reranking & Custom Meta Functions Demo\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. LLM-based context reranking by relevance\n",
    "2. Custom meta functions for filtering, ranking, and transforming context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable chat mode\n",
    "%llm_chat on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Some Context\n",
    "\n",
    "Let's create a variety of cells with different topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell about Python basics\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "    \n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell about machine learning\n",
    "import numpy as np\n",
    "\n",
    "# Simple linear regression example\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "y = 2 * X + 1\n",
    "print(f\"Linear relationship: y = 2x + 1\")\n",
    "print(f\"X: {X}\")\n",
    "print(f\"y: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is gradient descent and how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell about web development\n",
    "html_template = \"\"\"\n",
    "<html>\n",
    "  <head><title>My Page</title></head>\n",
    "  <body>\n",
    "    <h1>Welcome!</h1>\n",
    "    <p>This is a simple HTML page.</p>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "print(\"Basic HTML structure created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random cell about cooking\n",
    "recipe = {\n",
    "    \"name\": \"Chocolate Chip Cookies\",\n",
    "    \"ingredients\": [\"flour\", \"butter\", \"sugar\", \"eggs\", \"chocolate chips\"],\n",
    "    \"time\": \"30 minutes\"\n",
    "}\n",
    "print(f\"Recipe: {recipe['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Can you explain neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: LLM-Based Reranking\n",
    "\n",
    "Now let's rerank cells by relevance to a specific query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's see the current context order\n",
    "%llm_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerank by relevance to machine learning\n",
    "%llm_rerank \"machine learning and neural networks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the new order\n",
    "%llm_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just show ranking without reordering\n",
    "%llm_rerank --show \"web development\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only top 5 most relevant cells\n",
    "%llm_rerank --top=5 \"Python programming\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear reranking to restore original order\n",
    "%llm_rerank_clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Custom Meta Functions\n",
    "\n",
    "Define your own context processing logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%meta filter\n",
    "def filter_cells(messages):\n",
    "    \"\"\"Filter out cells that are too short or contain specific keywords.\"\"\"\n",
    "    filtered = []\n",
    "    \n",
    "    for msg in messages:\n",
    "        content = msg['content']\n",
    "        \n",
    "        # Skip very short messages\n",
    "        if len(content) < 20:\n",
    "            continue\n",
    "            \n",
    "        # Skip cells about cooking (as an example)\n",
    "        if 'recipe' in content.lower() or 'cooking' in content.lower():\n",
    "            continue\n",
    "            \n",
    "        filtered.append(msg)\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%meta ranking\n",
    "def rank_cells(messages, query):\n",
    "    \"\"\"Custom ranking based on keyword matching.\"\"\"\n",
    "    # Simple keyword-based ranking\n",
    "    query_words = set(query.lower().split())\n",
    "    \n",
    "    scored_messages = []\n",
    "    for msg in messages:\n",
    "        content_words = set(msg['content'].lower().split())\n",
    "        score = len(query_words.intersection(content_words))\n",
    "        scored_messages.append((score, msg))\n",
    "    \n",
    "    # Sort by score (descending)\n",
    "    scored_messages.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Return reordered messages\n",
    "    return [msg for score, msg in scored_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%meta transform\n",
    "def transform_context(messages):\n",
    "    \"\"\"Add metadata to each message.\"\"\"\n",
    "    transformed = []\n",
    "    \n",
    "    for i, msg in enumerate(messages):\n",
    "        # Add position and length metadata\n",
    "        new_msg = msg.copy()\n",
    "        new_msg['content'] = f\"[Position {i+1}, Length {len(msg['content'])}]\\n{msg['content']}\"\n",
    "        transformed.append(new_msg)\n",
    "    \n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List defined meta functions\n",
    "%llm_meta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the filter function\n",
    "%llm_apply_meta filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply custom ranking\n",
    "%llm_apply_meta ranking \"machine learning neural networks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all meta functions in sequence\n",
    "%llm_apply_meta all \"Python programming\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the transformed context\n",
    "%llm_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Advanced Meta Functions\n",
    "\n",
    "More sophisticated examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%meta ranking\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def rank_cells(messages, query):\n",
    "    \"\"\"Semantic ranking using TF-IDF-like scoring.\"\"\"\n",
    "    # Tokenize query\n",
    "    query_tokens = re.findall(r'\\w+', query.lower())\n",
    "    query_freq = Counter(query_tokens)\n",
    "    \n",
    "    scored = []\n",
    "    for msg in messages:\n",
    "        # Tokenize message\n",
    "        msg_tokens = re.findall(r'\\w+', msg['content'].lower())\n",
    "        msg_freq = Counter(msg_tokens)\n",
    "        \n",
    "        # Calculate similarity score\n",
    "        score = 0\n",
    "        for token, freq in query_freq.items():\n",
    "            if token in msg_freq:\n",
    "                # Higher score for more occurrences\n",
    "                score += min(freq, msg_freq[token]) * (1 + len(token) / 10)\n",
    "        \n",
    "        # Boost score for assistant responses about the topic\n",
    "        if msg['role'] == 'assistant' and any(t in msg_tokens for t in query_tokens):\n",
    "            score *= 1.5\n",
    "            \n",
    "        scored.append((score, msg))\n",
    "    \n",
    "    # Sort by score\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Return reordered, keeping at least some context\n",
    "    result = [msg for _, msg in scored]\n",
    "    \n",
    "    # Ensure we have at least 3 messages\n",
    "    if len(result) < 3 and len(messages) >= 3:\n",
    "        return result + messages[:3-len(result)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the new ranking\n",
    "%llm_apply_meta ranking \"neural networks gradient descent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You now have powerful tools for context management:\n",
    "\n",
    "1. **LLM-based reranking** - Let the AI intelligently reorder cells by relevance\n",
    "2. **Custom meta functions** - Define your own logic for filtering, ranking, and transforming\n",
    "3. **Flexible application** - Apply functions individually or in sequence\n",
    "\n",
    "This gives you complete control over what context the LLM sees and in what order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable chat mode\n",
    "%llm_chat off"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Kernel",
   "language": "python",
   "name": "llm_kernel"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}